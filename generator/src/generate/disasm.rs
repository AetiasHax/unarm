use anyhow::{bail, Context, Result};
use proc_macro2::{Literal, Span, TokenStream};
use quote::quote;
use syn::{
    parse_quote,
    visit_mut::{self, VisitMut},
    Expr, ExprLit, Ident, Lit,
};

use crate::{
    args::{ArgType, IsaArgs},
    isa::{Field, FieldValue, Flag, Isa, Opcode},
    iter::cartesian,
    search::SearchTree,
    token::HexLiteral,
};

pub fn generate_disasm(isa: &Isa, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
    // Generate opcode enum and mnemonics array
    let (opcode_enum_tokens, opcode_mnemonics_tokens, num_opcodes) = generate_opcode_tokens(&isa.opcodes);
    assert!(num_opcodes <= 256);
    let num_opcodes_token = Literal::usize_unsuffixed(num_opcodes);
    let opcode_max_token = Literal::usize_unsuffixed(num_opcodes - 1);

    // Generate opcode search function
    let mut opcodes = isa.opcodes.to_vec();
    let tree = SearchTree::optimize(&opcodes, u32::MAX).unwrap();
    let body = generate_search_node(Some(Box::new(tree)), &mut opcodes);
    let opcode_find_tokens = quote! {
        #[inline]
        pub fn find(code: u32, flags: &ParseFlags) -> Self {
            #body
            Opcode::Illegal
        }
    };

    // Generate field accessors
    let field_accessors_tokens = generate_field_accessors(isa, isa_args)?;

    // Generate modifier case enums
    let case_enums_tokens = generate_modifier_case_enums(isa);

    // Generate modifier accessors
    let modifier_accessors_tokens = generate_modifier_accessors(isa)?;

    // Generate tag functions
    let tag_functions_tokens = generate_tag_functions(isa);

    // Generate parse/defs/uses functions
    let parse_functions = generate_parse_functions(isa)?;
    let parse_functions_tokens = parse_functions.generate_parse_functions(isa_args, max_args, &num_opcodes_token)?;
    let defs_functions_tokens = parse_functions.generate_defs_functions(isa_args, max_args, &num_opcodes_token)?;
    let uses_functions_tokens = parse_functions.generate_uses_functions(isa_args, max_args, &num_opcodes_token)?;

    Ok(quote! {
        #![cfg_attr(rustfmt, rustfmt_skip)]
        #![allow(unused)]
        #![allow(clippy::double_parens, clippy::unnecessary_cast)]
        #[comment = " Generated by unarm-generator. Do not edit!"]

        use crate::{ArmVersion, ParseFlags, args::*, parse::ParsedIns};
        use super::Ins;

        #[doc = " These are the mnemonics of each opcode. Some mnemonics are duplicated due to them having multiple formats."]
        static OPCODE_MNEMONICS: [&str; #num_opcodes_token] = [#opcode_mnemonics_tokens];

        #[derive(Clone, Copy, Debug, Default, PartialEq, Eq)]
        #[repr(u8)]
        #[non_exhaustive]
        pub enum Opcode {
            #[doc = " Illegal or unknown"]
            #[default]
            Illegal = 0,
            #opcode_enum_tokens
        }
        impl Opcode {
            #opcode_find_tokens
            pub fn mnemonic(self) -> &'static str {
                OPCODE_MNEMONICS[self as usize]
            }
            pub fn count() -> usize {
                #num_opcodes_token
            }
        }
        impl From<u8> for Opcode {
            #[inline]
            fn from(value: u8) -> Self {
                if value > #opcode_max_token {
                    Self::Illegal
                } else {
                    #[comment = " Safety: The enum is repr(u8) and the value is within the enum's range"]
                    unsafe { core::mem::transmute::<u8, Self>(value) }
                }
            }
        }
        impl From<Opcode> for u8 {
            #[inline]
            fn from(value: Opcode) -> Self {
                value as u8
            }
        }

        impl Ins {
            #field_accessors_tokens
            #modifier_accessors_tokens
            #tag_functions_tokens
        }

        #case_enums_tokens

        #parse_functions_tokens

        #defs_functions_tokens

        #uses_functions_tokens
    })
}

fn generate_search_node(node: Option<Box<SearchTree>>, opcodes: &mut Vec<Opcode>) -> TokenStream {
    if let Some(node) = node {
        let bitmask_token = HexLiteral(node.bitmask);
        let pattern_token = HexLiteral(node.left_pattern);

        let (mut left, mut right) = node.filter(opcodes);
        let left_node = generate_search_node(node.left, &mut left);
        let right_node = generate_search_node(node.right, &mut right);

        let body = quote! {
            if (code & #bitmask_token) == #pattern_token {
                #left_node
            } else {
                #right_node
            }
        };
        body
    } else {
        // When bitmask A is a subset of B, then B must be first, otherwise we might never choose B
        opcodes.sort_unstable_by_key(|op| 32 - op.bitmask.count_ones());
        let opcode_checks = opcodes.iter().map(|op| {
            let bitmask_token = HexLiteral(op.bitmask);
            let pattern_token = HexLiteral(op.pattern);
            let variant_token = Ident::new(&op.enum_name(), Span::call_site());

            let code_mask = if op.bitmask != 0xffffffff {
                quote! { (code & #bitmask_token) }
            } else {
                quote! { code }
            };

            if op.flags.is_empty() {
                quote! {
                    if #code_mask == #pattern_token {
                        return Opcode::#variant_token;
                    }
                }
            } else {
                let cfg_checks = op
                    .flags
                    .iter()
                    .filter_map(|f| match f {
                        Flag::Ual(_) => None,
                        Flag::MinVersion(version) => {
                            let features = version
                                .feature_names()
                                .iter()
                                .map(|feature_name| quote! { feature = #feature_name });
                            Some(quote! { #[cfg(any( #(#features),* ))] })
                        }
                    })
                    .collect::<Vec<_>>();
                let flags_checks = op.flags.iter().map(|f| match f {
                    Flag::Ual(true) => quote! { flags.ual },
                    Flag::Ual(false) => quote! { !flags.ual },
                    Flag::MinVersion(version) => {
                        let variant_name = Ident::new(version.enum_variant_name(), Span::call_site());
                        quote! { flags.version >= ArmVersion::#variant_name }
                    }
                });
                let flags_expr = quote! {
                    #(#flags_checks)&&*
                };
                let token_stream = quote! {
                    #(#cfg_checks)*
                    if #flags_expr && #code_mask == #pattern_token {
                        return Opcode::#variant_token;
                    }
                };
                token_stream
            }
        });
        quote! {
            #(#opcode_checks)*
        }
    }
}

fn illegal_ins(max_args: usize) -> TokenStream {
    let illegal_args = illegal_ins_args(max_args);
    quote! {
        ParsedIns {
            mnemonic: "<illegal>",
            args: #illegal_args,
        }
    }
}

fn illegal_ins_args(max_args: usize) -> TokenStream {
    let illegal_args = (0..max_args).map(|_| quote! { Argument::None });
    quote! {
        [
            #(#illegal_args),*
        ]
    }
}

struct ParseFunctions<'a> {
    parse_functions: Vec<ParseFunction<'a>>,
}

impl ParseFunctions<'_> {
    fn generate_parse_functions(
        &self,
        isa_args: &IsaArgs,
        max_args: usize,
        num_opcodes_token: &Literal,
    ) -> Result<TokenStream> {
        let parse_functions = self
            .parse_functions
            .iter()
            .map(|pf| pf.create_parse_function(isa_args, max_args))
            .collect::<Result<Vec<_>>>()?;
        let parser_fns = self
            .parse_functions
            .iter()
            .map(|pf| Ident::new(&pf.parser_fn_name(), Span::call_site()))
            .collect::<Vec<_>>();
        let illegal_ins = illegal_ins(max_args);

        Ok(quote! {
            #(#parse_functions)*
            type MnemonicParser = fn(&mut ParsedIns, Ins, &ParseFlags);
            static MNEMONIC_PARSERS: [MnemonicParser; #num_opcodes_token] = [
                #(#parser_fns),*
            ];
            #[inline]
            pub fn parse(out: &mut ParsedIns, ins: Ins, flags: &ParseFlags) {
                if ins.op != Opcode::Illegal {
                    MNEMONIC_PARSERS[ins.op as usize](out, ins, flags);
                } else {
                    *out = #illegal_ins;
                }
            }
        })
    }

    fn generate_defs_functions(
        &self,
        isa_args: &IsaArgs,
        max_args: usize,
        num_opcodes_token: &Literal,
    ) -> Result<TokenStream> {
        let defs_functions = self
            .parse_functions
            .iter()
            .map(|pf| pf.create_defs_uses_function(ArgGroup::Defs, isa_args, max_args))
            .collect::<Result<Vec<_>>>()?;
        let defs_fns = self
            .parse_functions
            .iter()
            .map(|pf| Ident::new(&pf.defs_fn_name(), Span::call_site()))
            .collect::<Vec<_>>();
        let illegal_ins_args = illegal_ins_args(max_args);

        Ok(quote! {
            #(#defs_functions)*
            type DefsFn = fn(&mut Arguments, Ins, &ParseFlags);
            static DEFS_FNS: [DefsFn; #num_opcodes_token] = [
                #(#defs_fns),*
            ];
            #[inline]
            pub fn defs(out: &mut Arguments, ins: Ins, flags: &ParseFlags) {
                if ins.op != Opcode::Illegal {
                    DEFS_FNS[ins.op as usize](out, ins, flags);
                } else {
                    *out = #illegal_ins_args;
                }
            }
        })
    }

    fn generate_uses_functions(
        &self,
        isa_args: &IsaArgs,
        max_args: usize,
        num_opcodes_token: &Literal,
    ) -> Result<TokenStream> {
        let uses_functions = self
            .parse_functions
            .iter()
            .map(|pf| pf.create_defs_uses_function(ArgGroup::Uses, isa_args, max_args))
            .collect::<Result<Vec<_>>>()?;
        let uses_fns = self
            .parse_functions
            .iter()
            .map(|pf| Ident::new(&pf.uses_fn_name(), Span::call_site()))
            .collect::<Vec<_>>();
        let illegal_ins_args = illegal_ins_args(max_args);

        Ok(quote! {
            #(#uses_functions)*
            type UsesFn = fn(&mut Arguments, Ins, &ParseFlags);
            static USES_FNS: [UsesFn; #num_opcodes_token] = [
                #(#uses_fns),*
            ];
            #[inline]
            pub fn uses(out: &mut Arguments, ins: Ins, flags: &ParseFlags) {
                if ins.op != Opcode::Illegal {
                    USES_FNS[ins.op as usize](out, ins, flags);
                } else {
                    *out = #illegal_ins_args;
                }
            }
        })
    }
}

struct ParseFunction<'a> {
    opcode: Option<&'a Opcode>,
    modifier_cases: ModifierCases<'a>,
    /// Modifier cases in divided syntax, if it differs from unified syntax
    modifier_cases_divided: Option<ModifierCases<'a>>,
}

impl ParseFunction<'_> {
    fn parser_fn_name(&self) -> String {
        if let Some(opcode) = self.opcode {
            opcode.parser_name()
        } else {
            "parse_illegal".to_string()
        }
    }

    fn create_parse_function(&self, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        let fn_ident = Ident::new(&self.parser_fn_name(), Span::call_site());

        let fn_body = if let Some(modifier_cases_divided) = &self.modifier_cases_divided {
            let unified_parsed_ins = self
                .modifier_cases
                .create_token_stream(ArgGroup::Default, isa_args, max_args)?;
            let divided_parsed_ins = modifier_cases_divided.create_token_stream(ArgGroup::Default, isa_args, max_args)?;
            quote! {
                if flags.ual {
                    *out = #unified_parsed_ins;
                } else {
                    *out = #divided_parsed_ins;
                }
            }
        } else {
            let parsed_ins = self
                .modifier_cases
                .create_token_stream(ArgGroup::Default, isa_args, max_args)?;
            quote! {
                *out = #parsed_ins;
            }
        };

        // Wrap in SBO/SBZ checks if needed
        let fn_body = self.wrap_sbo_sbz_checks(ArgGroup::Default, max_args, fn_body);

        Ok(quote! {
            fn #fn_ident(out: &mut ParsedIns, ins: Ins, flags: &ParseFlags) {
                #fn_body
            }
        })
    }

    fn defs_fn_name(&self) -> String {
        if let Some(opcode) = self.opcode {
            opcode.defs_fn_name()
        } else {
            "defs_illegal".to_string()
        }
    }

    fn uses_fn_name(&self) -> String {
        if let Some(opcode) = self.opcode {
            opcode.uses_fn_name()
        } else {
            "uses_illegal".to_string()
        }
    }

    fn create_defs_uses_function(&self, arg_group: ArgGroup, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        let fn_name = match arg_group {
            ArgGroup::Default => panic!(),
            ArgGroup::Defs => self.defs_fn_name(),
            ArgGroup::Uses => self.uses_fn_name(),
        };
        let fn_ident = Ident::new(&fn_name, Span::call_site());

        let fn_body = if let Some(modifier_cases_divided) = &self.modifier_cases_divided {
            let unified_args = self.modifier_cases.create_token_stream(arg_group, isa_args, max_args)?;
            let divided_args = modifier_cases_divided.create_token_stream(arg_group, isa_args, max_args)?;
            quote! {
                if flags.ual {
                    *out = #unified_args;
                } else {
                    *out = #divided_args;
                }
            }
        } else {
            let args = self.modifier_cases.create_token_stream(arg_group, isa_args, max_args)?;
            quote! {
                *out = #args;
            }
        };

        // Wrap in SBO/SBZ checks if needed
        let fn_body = self.wrap_sbo_sbz_checks(arg_group, max_args, fn_body);

        Ok(quote! {
            fn #fn_ident(out: &mut Arguments, ins: Ins, flags: &ParseFlags) {
                #fn_body
            }
        })
    }

    fn wrap_sbo_sbz_checks(&self, arg_group: ArgGroup, max_args: usize, fn_body: TokenStream) -> TokenStream {
        if let Some(opcode) = self.opcode {
            let sbo_sbz_bitmask = opcode.sbo_sbz_bitmask();
            if sbo_sbz_bitmask != 0 {
                let illegal_ins = match arg_group {
                    ArgGroup::Default => illegal_ins(max_args),
                    ArgGroup::Defs => illegal_ins_args(max_args),
                    ArgGroup::Uses => illegal_ins_args(max_args),
                };

                let pattern = opcode.sbo_sbz_pattern();
                let bitmask = HexLiteral(sbo_sbz_bitmask);
                let pattern = HexLiteral(pattern);
                quote! {
                    if (ins.code & #bitmask) == #pattern {
                        #fn_body
                    } else {
                        *out = #illegal_ins;
                    }
                }
            } else {
                fn_body
            }
        } else {
            fn_body
        }
    }
}

struct ModifierCases<'a> {
    modifier_values: Vec<TokenStream>,
    cases: Vec<ModifierCase<'a>>,
}

impl ModifierCases<'_> {
    fn create_token_stream(&self, arg_group: ArgGroup, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        if self.cases.len() == 1 {
            match arg_group {
                ArgGroup::Default => return self.cases[0].create_parsed_ins(isa_args, max_args),
                ArgGroup::Defs => return self.cases[0].create_defs(isa_args, max_args),
                ArgGroup::Uses => return self.cases[0].create_uses(isa_args, max_args),
            }
        }

        let illegal_ins = match arg_group {
            ArgGroup::Default => illegal_ins(max_args),
            ArgGroup::Defs => illegal_ins_args(max_args),
            ArgGroup::Uses => illegal_ins_args(max_args),
        };

        let modifier_fields = &self.modifier_values;
        let cases: Result<Vec<TokenStream>> = match arg_group {
            ArgGroup::Default => self
                .cases
                .iter()
                .map(|case| case.create_parsed_ins(isa_args, max_args))
                .collect(),
            ArgGroup::Defs => self.cases.iter().map(|case| case.create_defs(isa_args, max_args)).collect(),
            ArgGroup::Uses => self.cases.iter().map(|case| case.create_uses(isa_args, max_args)).collect(),
        };
        let cases = cases?;
        Ok(quote! {
            match (#(#modifier_fields),*) {
                #(#cases),*,
                _ => #illegal_ins,
            }
        })
    }
}

struct ModifierCase<'a> {
    patterns: Vec<TokenStream>,
    mnemonic: String,
    args: Vec<OpcodeArgument<'a>>,
}

impl ModifierCase<'_> {
    fn create_parsed_ins(&self, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        let patterns = &self.patterns;
        let mnemonic = &self.mnemonic;
        let mut args = self
            .args
            .iter()
            .map(|arg| arg.create_argument(isa_args))
            .collect::<Result<Vec<_>>>()?;
        while args.len() < max_args {
            args.push(quote! { Argument::None });
        }

        let parsed_ins = quote! {
            ParsedIns {
                mnemonic: #mnemonic,
                args: [
                    #(#args),*
                ]
            }
        };
        if patterns.is_empty() {
            Ok(parsed_ins)
        } else {
            Ok(quote! {
                (#(#patterns),*) => #parsed_ins
            })
        }
    }

    fn create_defs(&self, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        let patterns = &self.patterns;
        let mut args = self
            .args
            .iter()
            .filter(|arg| arg.is_def)
            .map(|arg| arg.create_argument(isa_args))
            .collect::<Result<Vec<_>>>()?;
        while args.len() < max_args {
            args.push(quote! { Argument::None });
        }
        let arguments = quote! {
            [ #(#args),* ]
        };
        if patterns.is_empty() {
            Ok(arguments)
        } else {
            Ok(quote! {
                (#(#patterns),*) => #arguments
            })
        }
    }

    fn create_uses(&self, isa_args: &IsaArgs, max_args: usize) -> Result<TokenStream> {
        let patterns = &self.patterns;
        let mut args = self
            .args
            .iter()
            .filter(|arg| arg.is_use)
            .map(|arg| arg.create_argument(isa_args))
            .collect::<Result<Vec<_>>>()?;
        while args.len() < max_args {
            args.push(quote! { Argument::None });
        }
        let arguments = quote! {
            [ #(#args),* ]
        };
        if patterns.is_empty() {
            Ok(arguments)
        } else {
            Ok(quote! {
                (#(#patterns),*) => #arguments
            })
        }
    }
}

struct OpcodeArgument<'a> {
    field: &'a Field,
    is_def: bool,
    is_use: bool,
}

impl OpcodeArgument<'_> {
    fn create_argument(&self, isa_args: &IsaArgs) -> Result<TokenStream> {
        let accessor = Ident::new(&self.field.accessor_name(), Span::call_site());
        let arg = isa_args.get_arg(&self.field.arg)?;
        let arg_variant = Ident::new(&arg.pascal_case_name(), Span::call_site());

        Ok(quote! {
            Argument::#arg_variant(ins.#accessor())
        })
    }
}

fn generate_parse_functions<'a>(isa: &'a Isa) -> Result<ParseFunctions<'a>> {
    let mut parse_functions: Vec<ParseFunction<'a>> = vec![];

    parse_functions.push(ParseFunction {
        opcode: None,
        modifier_cases: ModifierCases {
            modifier_values: vec![],
            cases: vec![ModifierCase {
                patterns: vec![],
                mnemonic: "<illegal>".to_string(),
                args: vec![],
            }],
        },
        modifier_cases_divided: None,
    });

    for opcode in isa.opcodes.iter() {
        let parse_fn: ParseFunction = generate_parse_function(isa, opcode)?;
        parse_functions.push(parse_fn);
    }
    Ok(ParseFunctions { parse_functions })
}

#[derive(Clone, Copy)]
enum ArgGroup {
    Default,
    Defs,
    Uses,
}

fn generate_parse_function<'a>(isa: &'a Isa, opcode: &'a Opcode) -> Result<ParseFunction<'a>, anyhow::Error> {
    let (modifier_cases, modifier_cases_divided) = match (opcode.has_ual_changes(isa)?, opcode.ual_flag()) {
        (true, None) => (
            generate_modifier_cases(opcode, isa, true)?,
            Some(generate_modifier_cases(opcode, isa, false)?),
        ),
        (_, Some(false)) => (generate_modifier_cases(opcode, isa, false)?, None),
        (_, Some(true)) | (false, None) => (generate_modifier_cases(opcode, isa, true)?, None),
    };
    Ok(ParseFunction {
        opcode: Some(opcode),
        modifier_cases,
        modifier_cases_divided,
    })
}

fn generate_modifier_cases<'a>(opcode: &Opcode, isa: &'a Isa, ual: bool) -> Result<ModifierCases<'a>, anyhow::Error> {
    let modifiers = opcode.get_modifiers(isa, ual)?;
    let modifier_values: Result<Vec<_>> = modifiers
        .iter()
        .map(|modifier| {
            let accessor = Ident::new(&modifier.accessor_name(), Span::call_site());
            Ok(quote! { ins.#accessor() })
        })
        .collect();
    let modifier_values = modifier_values?;

    let args = &opcode.args;
    let defs = &opcode.defs;
    let uses = &opcode.uses;

    let opcode_args = args
        .iter()
        .filter_map(|arg| {
            let field = isa.get_field(arg);
            let Ok(field) = field else { return Some(field) };
            match (field.ual_flag(), ual) {
                (None, _) => Some(Ok(field)),
                // Remove fields that only belong in unified/divided syntax but not both
                (Some(a), b) if a == b => Some(Ok(field)),
                _ => None,
            }
        })
        .collect::<Result<Vec<_>>>()?;
    let modifier_cases = opcode.get_modifier_cases(isa, ual)?;

    let cases: Vec<ModifierCase> = {
        if modifier_cases.is_empty() {
            let mnemonic = opcode.name(ual).to_string();
            let args = generate_mnemonic_args(opcode_args, defs, uses)?;
            vec![ModifierCase {
                patterns: vec![],
                mnemonic,
                args,
            }]
        } else {
            let mut cases_vec: Vec<ModifierCase> = vec![];
            for cases in cartesian(&modifier_cases) {
                let case_values = cases
                    .iter()
                    .zip(modifiers.iter())
                    .map(|(case, modifier)| {
                        if modifier.pattern.is_some() {
                            if case.pattern != 0 {
                                quote! { true }
                            } else {
                                quote! { false }
                            }
                        } else {
                            let enum_name = Ident::new(&modifier.enum_name(), Span::call_site());
                            let variant_name = Ident::new(&case.variant_name(), Span::call_site());
                            quote! { #enum_name::#variant_name }
                        }
                    })
                    .collect();
                let suffix = cases.iter().map(|case| case.suffix(ual)).collect::<String>();
                let opcode_suffix = opcode.suffix.as_ref().map_or("", |s| s.suffix(ual));
                let mnemonic = if ual {
                    opcode.base_name().to_string() + opcode_suffix + &suffix
                } else {
                    opcode.base_name().to_string() + &suffix + opcode_suffix
                };

                let mut case_args = opcode_args.clone();
                let mut case_defs = defs.clone().to_vec();
                let mut case_uses = uses.clone().to_vec();
                for case in cases.iter() {
                    let case_arg_group = &case.args;
                    for arg in case_arg_group.iter() {
                        let arg = isa.get_field(arg)?;
                        case_args.push(arg);
                    }
                    case_defs.extend(case.defs.iter().cloned());
                    case_uses.extend(case.uses.iter().cloned());
                }

                let args = generate_mnemonic_args(case_args, &case_defs, &case_uses)?;
                cases_vec.push(ModifierCase {
                    patterns: case_values,
                    mnemonic: mnemonic.clone(),
                    args,
                });
            }
            cases_vec
        }
    };

    Ok(ModifierCases { modifier_values, cases })
}

fn generate_mnemonic_args<'a>(args: Vec<&'a Field>, defs: &[String], uses: &[String]) -> Result<Vec<OpcodeArgument<'a>>> {
    let args = args
        .iter()
        .map(|field| {
            Ok(OpcodeArgument {
                field,
                is_def: defs.contains(&field.name),
                is_use: uses.contains(&field.name),
            })
        })
        .collect::<Result<Vec<_>>>()?;
    Ok(args)
}

fn generate_modifier_accessors(isa: &Isa) -> Result<TokenStream> {
    let mut modifier_accessors_tokens = TokenStream::new();
    for modifier in isa.modifiers.iter() {
        let (inner, ret_type) = match (modifier.bitmask, modifier.pattern, &modifier.cases) {
            (Some(bitmask), Some(pattern), None) => {
                let bitmask_token = HexLiteral(bitmask);
                let pattern_token = HexLiteral(pattern);
                (
                    quote! { (self.code & #bitmask_token) == #pattern_token },
                    Ident::new("bool", Span::call_site()),
                )
            }
            (bitmask, None, Some(cases)) => {
                let enum_name = modifier.enum_name();
                let enum_ident = Ident::new(&enum_name, Span::call_site());

                let sorted_cases = {
                    let mut sorted_cases = Vec::from(cases.clone());
                    // When bitmask A is a subset of B, then B must be first, otherwise we will never choose B
                    sorted_cases.sort_by_key(|case| 32 - case.bitmask.unwrap_or(0).count_ones());
                    sorted_cases
                };

                if let Some(bitmask) = bitmask {
                    let bitmask_token = HexLiteral(bitmask);
                    let mut match_tokens = TokenStream::new();
                    for case in sorted_cases.iter() {
                        let pattern_token = HexLiteral(case.pattern);
                        let variant_name = case.variant_name();
                        let variant_ident = Ident::new(&variant_name, Span::call_site());
                        match_tokens.extend(quote! {
                            #pattern_token => #enum_ident::#variant_ident,
                        });
                    }

                    (
                        quote! {
                            match self.code & #bitmask_token {
                                #match_tokens
                                _ => #enum_ident::Illegal,
                            }
                        },
                        enum_ident,
                    )
                } else {
                    let mut if_tokens = vec![];
                    let mut else_case = quote! { { #enum_ident::Illegal } };
                    for case in sorted_cases.iter() {
                        let bitmask = case.bitmask.with_context(|| {
                            format!("Modifier case '{}' in modifier '{}' has no bitmask", case.name, modifier.name)
                        })?;
                        let bitmask_token = HexLiteral(bitmask);
                        let pattern_token = HexLiteral(case.pattern);
                        let variant_name = case.variant_name();
                        let variant_ident = Ident::new(&variant_name, Span::call_site());
                        if bitmask != 0 {
                            if_tokens.push(quote! {
                                if (self.code & #bitmask_token) == #pattern_token {
                                    #enum_ident::#variant_ident
                                }
                            });
                        } else {
                            else_case = quote! { { #enum_ident::#variant_ident } };
                        }
                    }

                    (
                        quote! {
                            #(#if_tokens)else*
                            else #else_case
                        },
                        enum_ident,
                    )
                }
            }
            (None, Some(_), None) => bail!("Can't generate modifier accessor '{}' with only a pattern", modifier.name),
            (_, Some(_), Some(_)) => bail!(
                "Can't generate modifier accessor '{}' with a pattern and cases",
                modifier.name
            ),
            (Some(_), None, None) => bail!("Can't generate modifier accessor '{}' with only a bitmask", modifier.name),
            (None, None, None) => bail!(
                "Can't generate modifier accessor '{}' without a pattern, bitmask and/or cases",
                modifier.name
            ),
        };

        let doc = modifier.doc();
        let fn_name = Ident::new(&modifier.accessor_name(), Span::call_site());

        modifier_accessors_tokens.extend(quote! {
            #[doc = #doc]
            #[inline(always)]
            pub const fn #fn_name(&self) -> #ret_type {
                #inner
            }
        })
    }
    Ok(modifier_accessors_tokens)
}

fn generate_modifier_case_enums(isa: &Isa) -> TokenStream {
    let mut case_enums_tokens = TokenStream::new();
    for modifier in isa.modifiers.iter() {
        if let Some(cases) = &modifier.cases {
            let mut variants_tokens = TokenStream::new();
            for case in cases.iter() {
                let variant_name = case.variant_name();
                let variant_ident = Ident::new(&variant_name, Span::call_site());
                let doc = case.doc();
                variants_tokens.extend(quote! {
                    #[doc = #doc]
                    #variant_ident,
                });
            }
            let enum_name = modifier.enum_name();
            let enum_ident = Ident::new(&enum_name, Span::call_site());
            let doc = modifier.doc();
            case_enums_tokens.extend(quote! {
                #[doc = #doc]
                #[derive(Debug, Clone, Copy, PartialEq, Eq)]
                pub enum #enum_ident {
                    Illegal,
                    #variants_tokens
                }
            })
        }
    }
    case_enums_tokens
}

fn generate_field_accessors(isa: &Isa, isa_args: &IsaArgs) -> Result<TokenStream> {
    let accessors = isa
        .fields
        .iter()
        .map(|field| {
            let arg = isa_args.get_arg(&field.arg)?;
            let body = match &arg.r#type {
                ArgType::Struct(members) => {
                    let values = if let FieldValue::Struct(values) = &field.value {
                        values
                    } else {
                        bail!("Value of field '{}' must be a struct", field.name);
                    };

                    let struct_ident = Ident::new(&arg.pascal_case_name(), Span::call_site());
                    let struct_members = members
                        .iter()
                        .map(|(name, member)| {
                            let value = values.get(name).with_context(|| {
                                format!("Member '{}' missing from struct value in field '{}'", name, field.name)
                            })?;
                            let expr = generate_argument_expr(value, field)?;
                            let expr = match &member.r#type {
                                ArgType::Struct(_) => {
                                    bail!("Nested structs (in argument '{}') are not supported", arg.name);
                                }
                                ArgType::Enum(_) => {
                                    bail!("Nested enums (in argument '{}') are not supported", arg.name);
                                }
                                ArgType::U32 => expr,
                                ArgType::I32 => quote! { (#expr) as i32 },
                                ArgType::Bool => {
                                    if let FieldValue::Bool(_) = value {
                                        quote! { #expr }
                                    } else {
                                        quote! { (#expr) != 0 }
                                    }
                                }
                                ArgType::Custom(custom_name) => {
                                    let custom_type = isa_args.get_type(custom_name)?;
                                    let custom_ident = Ident::new(&custom_type.pascal_case_name(), Span::call_site());
                                    quote! { #custom_ident::parse(#expr) }
                                }
                            };

                            let ident = Ident::new(name, Span::call_site());
                            Ok(quote! {
                                #ident: #expr
                            })
                        })
                        .collect::<Result<Vec<_>>>()?;

                    quote! {
                        #struct_ident {
                            #(#struct_members),*
                        }
                    }
                }
                ArgType::Enum(_) => {
                    let enum_ident = Ident::new(&arg.pascal_case_name(), Span::call_site());
                    let expr = generate_argument_expr(&field.value, field)?;
                    quote! { #enum_ident::parse(#expr) }
                }
                ArgType::U32 => generate_argument_expr(&field.value, field)?,
                ArgType::I32 => {
                    let body = generate_argument_expr(&field.value, field)?;
                    quote! { (#body) as i32 }
                }
                ArgType::Bool => generate_argument_expr(&field.value, field)?,
                ArgType::Custom(custom_name) => {
                    let custom_type = isa_args.get_type(custom_name)?;
                    let custom_ident = Ident::new(&custom_type.pascal_case_name(), Span::call_site());
                    let expr = generate_argument_expr(&field.value, field)?;
                    quote! { #custom_ident::parse(#expr) }
                }
            };

            let arg_ident = Ident::new(&arg.pascal_case_name(), Span::call_site());
            let return_type = match arg.r#type {
                ArgType::Struct(_) => quote! { #arg_ident },
                ArgType::Enum(_) => quote! { #arg_ident },
                ArgType::U32 => quote! { u32 },
                ArgType::I32 => quote! { i32 },
                ArgType::Bool => quote! { bool },
                ArgType::Custom(_) => quote! { #arg_ident },
            };

            let doc = field.doc();
            let accessor_ident = Ident::new(&field.accessor_name(), Span::call_site());
            Ok(quote! {
                #[doc = #doc]
                #[inline(always)]
                pub fn #accessor_ident(&self) -> #return_type {
                    #body
                }
            })
        })
        .collect::<Result<Vec<_>>>()?;

    Ok(quote! {
        #(#accessors)*
    })
}

struct FoldFieldExpr;

impl VisitMut for FoldFieldExpr {
    fn visit_expr_mut(&mut self, node: &mut Expr) {
        if let Expr::MethodCall(call) = node {
            let lhs = call.receiver.as_ref();
            match call.method.to_string().as_str() {
                "bits" => {
                    if call.args.len() != 2 {
                        return;
                    }
                    let start = get_literal_value(&call.args[0]);
                    let end = get_literal_value(&call.args[1]);

                    let shift = start;
                    let mask = HexLiteral((1 << (end - start)) - 1);
                    if shift == 0 {
                        *node = parse_quote! { (#lhs & #mask) };
                    } else {
                        let shift = Literal::i32_unsuffixed(shift);
                        *node = parse_quote! { ((#lhs >> #shift) & #mask) };
                    }
                }
                "bit" => {
                    if call.args.len() != 1 {
                        return;
                    }
                    let bit = get_literal_value(&call.args[0]);
                    let mask = HexLiteral(1 << bit);
                    *node = parse_quote! { ((#lhs & #mask) != 0) };
                }
                "negate" => {
                    if call.args.len() != 1 {
                        return;
                    }
                    let rhs = call.args[0].clone();
                    *node = parse_quote! { {
                        let value = #lhs as i32;
                        if #rhs {
                            value
                        } else {
                            -value
                        }
                    } };
                }
                "sign_extend" => {
                    if call.args.len() != 1 {
                        return;
                    }
                    let rhs = call.args[0].clone();
                    *node = parse_quote! {
                        ((#lhs as i32) << #rhs >> #rhs)
                    };
                }
                "arm_shift" => {
                    if call.args.len() != 1 {
                        return;
                    }
                    let rhs = call.args[0].clone();
                    *node = parse_quote! { {
                        let value = #lhs;
                        match #rhs {
                            1 | 2 => if value == 0 { 32 } else { value },
                            _ => value
                        }
                    } };
                }
                _ => {}
            }
        }
        visit_mut::visit_expr_mut(self, node);
    }
}

fn get_literal_value(expr: &Expr) -> i32 {
    if let Expr::Lit(ExprLit {
        attrs: _,
        lit: Lit::Int(int),
    }) = expr
    {
        int.base10_parse().unwrap_or(i32::MIN)
    } else {
        i32::MIN
    }
}

fn generate_argument_expr(value: &FieldValue, field: &Field) -> Result<TokenStream, anyhow::Error> {
    let expr = match value {
        FieldValue::Bits(range) => {
            let start = Literal::u8_unsuffixed(range.0.start);
            let end = Literal::u8_unsuffixed(range.0.end);
            let mut expr = parse_quote! { self.code.bits(#start,#end) };
            FoldFieldExpr.visit_expr_mut(&mut expr);
            quote! { #expr }
        }
        FieldValue::Bool(value) => {
            if *value {
                quote! { true }
            } else {
                quote! { false }
            }
        }
        FieldValue::U32(value) => {
            let value = Literal::u32_unsuffixed(*value);
            quote! { #value }
        }
        FieldValue::Struct(_) => {
            bail!("Nested structs (in field '{}') are not supported", field.name);
        }
        FieldValue::Expr(expr) => {
            let mut expr = syn::parse_str(expr)?;
            FoldFieldExpr.visit_expr_mut(&mut expr);
            quote! { #expr }
        }
    };
    Ok(expr)
}

fn generate_opcode_tokens(sorted_opcodes: &[Opcode]) -> (TokenStream, TokenStream, usize) {
    let mut opcode_enum_tokens = TokenStream::new();
    let mut opcode_mnemonics_tokens = TokenStream::new();
    let num_opcodes = sorted_opcodes.len() + 1;

    opcode_mnemonics_tokens.extend(quote! { "<illegal>", });

    for (i, opcode) in sorted_opcodes.iter().enumerate() {
        let name = &opcode.name(true);
        opcode_mnemonics_tokens.extend(quote! { #name, });

        let enum_name = Ident::new(&opcode.enum_name(), Span::call_site());
        let enum_value = Literal::u8_unsuffixed((i + 1).try_into().unwrap());
        let doc = opcode.doc(true);

        opcode_enum_tokens.extend(quote! {
            #[doc = #doc]
            #enum_name = #enum_value,
        });
    }
    (opcode_enum_tokens, opcode_mnemonics_tokens, num_opcodes)
}

fn generate_tag_functions(isa: &Isa) -> TokenStream {
    let modifier_tags = isa.modifiers.iter().map(|modifier| {
        let fn_name = Ident::new(&modifier.tag_function_name(), Span::call_site());
        let match_arms = isa
            .opcodes
            .iter()
            .filter(|opcode| opcode.has_modifier(&modifier.name))
            .map(|opcode| {
                let enum_name = Ident::new(&opcode.enum_name(), Span::call_site());
                quote! { Opcode::#enum_name }
            });
        let doc = modifier.doc();

        quote! {
            #[doc = #doc]
            pub fn #fn_name(&self) -> bool {
                matches!(self.op, #(#match_arms)|*)
            }
        }
    });

    let custom_tags = isa.tags.iter().map(|tag| {
        let fn_name = Ident::new(&tag.name, Span::call_site());
        let match_arms = isa.opcodes.iter().filter(|opcode| opcode.has_tag(&tag.name)).map(|opcode| {
            let enum_name = Ident::new(&opcode.enum_name(), Span::call_site());
            quote! { Opcode::#enum_name }
        });
        let doc = format!(" {}", tag.desc);

        quote! {
            #[doc = #doc]
            pub fn #fn_name(&self) -> bool {
                matches!(self.op, #(#match_arms)|*)
            }
        }
    });

    let tag_functions = modifier_tags.chain(custom_tags);
    quote! {
        #(#tag_functions)*
    }
}
